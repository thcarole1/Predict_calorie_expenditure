{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d1c7b7-63f2-4660-802d-803dfda16fb0",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b72a675-ecf1-4545-870f-66466112a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "## Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "\n",
    "## Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Basic cleaning\n",
    "## Variance\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_log_error, make_scorer, mean_squared_error\n",
    "from scipy.stats import iqr\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.compose import make_column_transformer, TransformedTargetRegressor\n",
    "from sklearn.linear_model import SGDRegressor, Lasso, ElasticNet, Perceptron,SGDRegressor,Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import QuantileTransformer \n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c77450a-d497-496a-8e69-0f4e9dfdeb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cols_outliers(df):\n",
    "        \"\"\"\n",
    "    Extract the columns with outliers.\n",
    "    Args:\n",
    "        df (DataFrame): Raw data\n",
    "    Returns:\n",
    "        - a list of numerical columns with outliers\n",
    "        - a list of nnumerical columns without outliers\n",
    "    \"\"\"\n",
    "        # Identify the columns with outliers\n",
    "        numerical_columns_w_outliers = []\n",
    "        numerical_columns_no_outliers = []\n",
    "        \n",
    "        num_df = df.select_dtypes(include='number')\n",
    "        numerical_columns = num_df.columns\n",
    "        \n",
    "        for col in numerical_columns: \n",
    "            # Calculate IQR\n",
    "            iqr_value = iqr(df[col],nan_policy='omit')        \n",
    "            #Calculate 1st quartile\n",
    "            q1 = np.percentile(df[col],25)        \n",
    "            #Calculate 3rd quartile\n",
    "            q3 = np.percentile(df[col],75)        \n",
    "            #Calculate lower limit below which data point is considered an outlier\n",
    "            outlier_lim_low = q1 - 1.5 * iqr_value\n",
    "        \n",
    "            #Calculate higher limit above which data point is considered an outlier\n",
    "            outlier_lim_high = q3 + 1.5 * iqr_value\n",
    "            \n",
    "            #Calculate number of 'low' outliers\n",
    "            outlier_condition_low = df[col] < outlier_lim_low\n",
    "            number_outliers_low = len(df[outlier_condition_low][col])\n",
    "            \n",
    "            #Calculate number of 'high' outliers\n",
    "            outlier_condition_high = df[col] > outlier_lim_high\n",
    "            number_outliers_high = len(df[outlier_condition_high][col])\n",
    "            \n",
    "            #Calculate total number of outliers\n",
    "            number_outliers_total = number_outliers_low + number_outliers_high\n",
    "            \n",
    "            #If any outliers in column, column is added to a list of columns with outliers\n",
    "            if number_outliers_total > 0:\n",
    "                numerical_columns_w_outliers.append(col)\n",
    "            elif number_outliers_total == 0:\n",
    "                numerical_columns_no_outliers.append(col)\n",
    "\n",
    "        return numerical_columns_w_outliers, numerical_columns_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "180bfa60-34db-498f-a2f3-500f4b6dc4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(df):\n",
    "    # Check number of rows before removing duplicates\n",
    "    print(f\"Number of rows : {len(df)}\")\n",
    "\n",
    "    # Compute the number of duplicated rows\n",
    "    num_dups = df.duplicated().sum()\n",
    "    \n",
    "    print(f\"Number of duplicated rows : {num_dups}\")\n",
    "\n",
    "    if df.duplicated().any():\n",
    "        # Remove duplicates\n",
    "        df_no_duplicates = df.drop_duplicates()\n",
    "        print(f\"{num_dups} duplicated row(s) removed\")\n",
    "        return df_no_duplicates\n",
    "    else:\n",
    "        return \"No duplicated rows found !\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae1e8b4-6ee7-4045-b9a3-27e2b30cb1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "def load_dataset(filename, target):\n",
    "    # load the dataset\n",
    "    data = pd.read_csv(filename, index_col='id') \n",
    "\n",
    "    #Check duplicates (Any duplicated rows are dropped)\n",
    "    data_no_dups = check_duplicates(data)\n",
    "    \n",
    "    # split into input and output variables\n",
    "    X = data_no_dups.drop(columns=[target])\n",
    "    y = data_no_dups[[target]]\n",
    "\n",
    "    # Display shapes\n",
    "    display(f\"Shape of X : {X.shape}\")\n",
    "    display(f\"Shape of y : {y.shape}\")\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f55df2b7-c74d-4950-9752-9dd081186c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root mean squared logaritmic error\n",
    "def root_mean_squared_log_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred, squared=True))\n",
    "\n",
    "# Define a RMSLE scorer\n",
    "rmsle_scorer = make_scorer(root_mean_squared_log_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db6d5b8-b36e-44da-a6a2-9ba8ca47fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_input_data(X):\n",
    "#     # Prepare features columns names\n",
    "#     categorical_columns = X.select_dtypes(exclude='number').columns.tolist()\n",
    "#     numerical_columns = X.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "#     # Prepare Column Transformer (input features)\n",
    "#     preproc = make_column_transformer((OneHotEncoder(drop='if_binary', sparse_output=False),categorical_columns),(MinMaxScaler(), numerical_columns))\n",
    "\n",
    "#     return preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cdaa7a1-ea43-4c94-97cd-903ed3ea62ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_input_data(X):\n",
    "#     # Prepare features columns names\n",
    "#     categorical_columns = X.select_dtypes(exclude='number').columns.tolist()\n",
    "#     numerical_columns = X.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "#     # Prepare Column Transformer (input features)\n",
    "#     preproc = make_column_transformer((OneHotEncoder(drop='if_binary', sparse_output=False),categorical_columns),(RobustScaler(), numerical_columns))\n",
    "\n",
    "#     return preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6288ac49-33a3-4ae5-8037-aca1a0449a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input_data(X):\n",
    "    # Prepare features columns names\n",
    "    categorical_columns = X.select_dtypes(exclude='number').columns.tolist()\n",
    "    numerical_columns = X.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "    # Prepare Column Transformer (input features)\n",
    "    preproc = make_column_transformer((OneHotEncoder(drop='if_binary', sparse_output=False),categorical_columns),\n",
    "                                      (QuantileTransformer(n_quantiles=100, output_distribution='uniform'), numerical_columns))\n",
    "    return preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a4b7e4c-8d0a-4b21-888c-d116f43e4ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_input_data(X):\n",
    "#     # Prepare features columns names\n",
    "#     categorical_columns = X.select_dtypes(exclude='number').columns.tolist()\n",
    "#     numerical_columns_w_outliers, numerical_columns_no_outliers = extract_cols_outliers(X)\n",
    "\n",
    "#     # Prepare Column Transformer (input features)\n",
    "#     preproc = make_column_transformer((OneHotEncoder(drop='if_binary', sparse_output=False),categorical_columns),\n",
    "#                                       (MinMaxScaler(), numerical_columns_no_outliers),\n",
    "#                                       (RobustScaler(), numerical_columns_w_outliers))\n",
    "\n",
    "#     return preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1b6ef3-da8d-4cc5-8fd4-9d5b96a39fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target\n",
    "def preprocess_output_data(y):\n",
    "    # Apply log1p transform to y\n",
    "    y_log = np.log1p(y)\n",
    "    return y_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06cbec20-9949-4c45-b02d-4486a019179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a given model using cross-validation \n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1) \n",
    "    scores = cross_val_score(model, X, y, scoring=rmsle_scorer, cv=cv, n_jobs=-1) \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3f1e462-5de9-41f7-802a-7bf4571d4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_model_performance(scores):\n",
    "    mean_rmsle = -np.mean(n_scores)\n",
    "    std_rmsle = np.std(n_scores)\n",
    "    return mean_rmsle, std_rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb0dcd21-4cbc-4bfb-92ec-77c16948d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model (preprocessing + actual model)\n",
    "def get_models(X_train, models_dict):\n",
    "    # Preprocess input data\n",
    "    preproc = preprocess_input_data(X_train)\n",
    "\n",
    "    # define and configure the model\n",
    "    pipeline = make_pipeline(preproc,model)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb193720-1603-4be9-83f0-5d5a26b246a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get model (preprocessing + actual model)\n",
    "# def get_models(X_train):\n",
    "#     # Preprocess input data\n",
    "#     preproc = preprocess_input_data(X_train)\n",
    "\n",
    "#     # define and configure the model\n",
    "#     model = LinearRegression()\n",
    "#     pipeline = make_pipeline(preproc,model)\n",
    "#     return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6033ff24-7abe-457b-a075-572fee8ec20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Paths\n",
    "# calorie_train_data_path = \"../data/raw_data/train.csv\"\n",
    "# target_name = \"Calories\"\n",
    "\n",
    "# # Load dataset\n",
    "# X,y = load_dataset(calorie_train_data_path,target_name)\n",
    "\n",
    "# # split into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1) \n",
    "\n",
    "# # Preprocess output data\n",
    "# y_train_log = preprocess_output_data(y_train)\n",
    "\n",
    "# # Define pipeline\n",
    "# models_dict = {\n",
    "#                 'LinearRegression' : LinearRegression(),\n",
    "#                 'Ridge': Ridge(random_state=1),\n",
    "#                 'Lasso' : Lasso(random_state=1),            \n",
    "#                 'ElasticNet' : ElasticNet(random_state=1),         \n",
    "#                 'DecisionTreeRegressor' : DecisionTreeRegressor(random_state=1),\n",
    "#                 'KNeighborsRegressor':KNeighborsRegressor()\n",
    "#                 # 'SGDRegressor' : SGDRegressor(random_state=1),\n",
    "#             }\n",
    "\n",
    "# for model_name, model in models_dict.items():\n",
    "#     # Get preprocessing and model chained\n",
    "#     pipeline = get_models(X_train, model)\n",
    "\n",
    "#     # evaluate a given model using cross-validation\n",
    "#     n_scores = evaluate_model(pipeline, X_train, y_train_log)\n",
    "\n",
    "#     # report model performance\n",
    "#     mean_rmsle, std_rmsle = report_model_performance(n_scores)\n",
    "#     print(f\"> {model_name} RMSLE: {mean_rmsle:.7f} ({std_rmsle:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c7652-76d5-437e-8835-f9292f21c4c7",
   "metadata": {},
   "source": [
    "I choose to use **DecisionTreeRegressor()** as it leads to the best results in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72c3c73e-ae71-43da-afd0-18e90f2a22c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Paths\n",
    "# calorie_train_data_path = \"../data/raw_data/train.csv\"\n",
    "# target_name = \"Calories\"\n",
    "\n",
    "# # Load dataset\n",
    "# X,y = load_dataset(calorie_train_data_path,target_name)\n",
    "\n",
    "# # split into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1) \n",
    "\n",
    "# # Preprocess output data\n",
    "# y_train_log = preprocess_output_data(y_train)\n",
    "\n",
    "# # Prepare features columns names\n",
    "# categorical_columns = X_train.select_dtypes(exclude='number').columns.tolist()\n",
    "# numerical_columns = X_train.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# # n_quants = [10, 50, 100, 500, 1000]\n",
    "# n_quants = np.arange(10, 1000, 100)\n",
    "\n",
    "# for i, n in enumerate(n_quants):\n",
    "#         # Prepare Column Transformer (input features)\n",
    "#         preproc = make_column_transformer((OneHotEncoder(drop='if_binary', sparse_output=False),categorical_columns),\n",
    "#                                           (QuantileTransformer(n_quantiles=n, output_distribution='uniform'), numerical_columns))\n",
    "\n",
    "#         # define and configure the model\n",
    "#         pipeline = make_pipeline(preproc,DecisionTreeRegressor(random_state=1))\n",
    "\n",
    "#         # evaluate a given model using cross-validation\n",
    "#         n_scores = evaluate_model(pipeline, X_train, y_train_log)\n",
    "\n",
    "#         # report model performance\n",
    "#         mean_rmsle, std_rmsle = report_model_performance(n_scores)\n",
    "#         print(f\"> {n} RMSLE: {mean_rmsle:.7f} ({std_rmsle:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8a921ee-c413-406f-8e0b-0d9b6a18c614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows : 750000\n",
      "Number of duplicated rows : 2841\n",
      "2841 duplicated row(s) removed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Shape of X : (747159, 7)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Shape of y : (747159, 1)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> RMSLE: 0.0249189 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "calorie_train_data_path = \"../data/raw_data/train.csv\"\n",
    "target_name = \"Calories\"\n",
    "\n",
    "# Load dataset\n",
    "X,y = load_dataset(calorie_train_data_path,target_name)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1) \n",
    "\n",
    "# Preprocess output data\n",
    "y_train_log = preprocess_output_data(y_train)\n",
    "\n",
    "# Prepare features columns names\n",
    "categorical_columns = X_train.select_dtypes(exclude='number').columns.tolist()\n",
    "numerical_columns = X_train.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Prepare Column Transformer (input features)\n",
    "preproc = make_column_transformer((OneHotEncoder(drop='if_binary', sparse_output=False),categorical_columns),\n",
    "                                  (QuantileTransformer(n_quantiles=10, output_distribution='uniform'), numerical_columns))\n",
    "\n",
    "# define and configure the model\n",
    "pipeline = make_pipeline(preproc,DecisionTreeRegressor(random_state=1))\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "n_scores = evaluate_model(pipeline, X_train, y_train_log)\n",
    "\n",
    "# report model performance\n",
    "mean_rmsle, std_rmsle = report_model_performance(n_scores)\n",
    "print(f\"> RMSLE: {mean_rmsle:.7f} ({std_rmsle:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2e955-2f7a-41a8-adea-b861837155c1",
   "metadata": {},
   "source": [
    "I chose to use **n_quantiles=10** leading to best results in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45e0ab69-cf67-49cf-8fa0-26d0a4120320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows : 750000\n",
      "Number of duplicated rows : 2841\n",
      "2841 duplicated row(s) removed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Shape of X : (747159, 7)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Shape of y : (747159, 1)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102083</th>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135855</th>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81092</th>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112227</th>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147816</th>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299109</th>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91423</th>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104015</th>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86823</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190833</th>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246563 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "id           \n",
       "102083   64.0\n",
       "135855  146.0\n",
       "81092    86.0\n",
       "112227   80.0\n",
       "147816  178.0\n",
       "...       ...\n",
       "299109   19.0\n",
       "91423    53.0\n",
       "104015   65.0\n",
       "86823    21.0\n",
       "190833   38.0\n",
       "\n",
       "[246563 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102083</th>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135855</th>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81092</th>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112227</th>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147816</th>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299109</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91423</th>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104015</th>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86823</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190833</th>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246563 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Calories\n",
       "id              \n",
       "102083      65.0\n",
       "135855     147.0\n",
       "81092       84.0\n",
       "112227      75.0\n",
       "147816     177.0\n",
       "...          ...\n",
       "299109      18.0\n",
       "91423       50.0\n",
       "104015      66.0\n",
       "86823       21.0\n",
       "190833      36.0\n",
       "\n",
       "[246563 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Paths\n",
    "calorie_train_data_path = \"../data/raw_data/train.csv\"\n",
    "target_name = \"Calories\"\n",
    "\n",
    "# Load dataset\n",
    "X,y = load_dataset(calorie_train_data_path,target_name)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1) \n",
    "\n",
    "# Preprocess output data\n",
    "y_train_log = preprocess_output_data(y_train)\n",
    "\n",
    "# Prepare features columns names\n",
    "categorical_columns = X_train.select_dtypes(exclude='number').columns.tolist()\n",
    "numerical_columns = X_train.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Prepare Column Transformer (input features)\n",
    "preproc = make_column_transformer((OneHotEncoder(drop='if_binary', sparse_output=False),categorical_columns),\n",
    "                                  (QuantileTransformer(n_quantiles=10, output_distribution='uniform'), numerical_columns))\n",
    "\n",
    "# define and configure the model\n",
    "pipeline = make_pipeline(preproc,DecisionTreeRegressor(random_state=1))\n",
    "\n",
    "# Fit pipeline\n",
    "pipeline.fit(X_train, y_train_log)\n",
    "\n",
    "# Predict and inverse log\n",
    "y_pred_log = pipeline.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_pred = pd.DataFrame(y_pred, index=y_test.index)\n",
    "display(y_pred)\n",
    "display(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eafea927-6a29-44bf-8a18-141a9407edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit pipeline\n",
    "# pipeline.fit(X_train, y_train_log)\n",
    "\n",
    "# # Predict and inverse log\n",
    "# y_pred_log = pipeline.predict(X_test)\n",
    "# y_pred = np.expm1(y_pred_log)\n",
    "# y_pred = pd.DataFrame(y_pred, index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5788c525-3c32-4985-b0e4-b06277a756dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
